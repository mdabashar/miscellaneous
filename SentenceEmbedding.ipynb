{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpified code for Sentence Embedding (SIF)\n",
    "\n",
    "The original code of the following paper is a complete solution for sentence embedding, so it contains lots of things together. However, in many cases, we have our word embeddings, and we just need to learn the sentence embeddings. Therefore, to simplify it, I am using only the sentence embedding part (i.e. get_weighted_average(), compute_pc(), remove_pc() and SIF_embedding() functions) from the original code. I am generating word embedding using word2vec from gensim library. \n",
    "\n",
    "### Source\n",
    "Paper: A SIMPLE BUT TOUGH-TO-BEAT BASELINE FOR SENTENCE EMBEDDINGS by Sanjeev Arora, Yingyu Liang and Tengyu Ma\n",
    "Link: https://openreview.net/pdf?id=SyK00v5xx\n",
    "\n",
    "Original Code at GitHub: https://github.com/PrincetonML/SIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_average(We, x, w):\n",
    "    \"\"\"\n",
    "    Compute the weighted average vectors\n",
    "    :param We: We[i,:] is the vector for word i\n",
    "    :param x: x[i, :] are the indices of the words in sentence i\n",
    "    :param w: w[i, :] are the weights for the words in sentence i\n",
    "    :return: emb[i, :] are the weighted average vector for sentence i\n",
    "    \"\"\"\n",
    "    n_samples = x.shape[0]\n",
    "    emb = np.zeros((n_samples, We.shape[1]))\n",
    "    for i in range(n_samples):\n",
    "        emb[i] = np.dot(w[i], We[x[i]]) / np.count_nonzero(w[i])\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pc(X,npc=1):\n",
    "    \"\"\"\n",
    "    Compute the principal components. DO NOT MAKE THE DATA ZERO MEAN!\n",
    "    :param X: X[i,:] is a data point\n",
    "    :param npc: number of principal components to remove\n",
    "    :return: component_[i,:] is the i-th pc\n",
    "    \"\"\"\n",
    "    svd = TruncatedSVD(n_components=npc, n_iter=7, random_state=0)\n",
    "    svd.fit(X)\n",
    "    return svd.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pc(X, npc=1):\n",
    "    \"\"\"\n",
    "    Remove the projection on the principal components\n",
    "    :param X: X[i,:] is a data point\n",
    "    :param npc: number of principal components to remove\n",
    "    :return: XX[i, :] is the data point after removing its projection\n",
    "    \"\"\"\n",
    "    pc = compute_pc(X, npc)\n",
    "    if npc==1:\n",
    "        XX = X - X.dot(pc.transpose()) * pc\n",
    "    else:\n",
    "        XX = X - X.dot(pc.transpose()).dot(pc)\n",
    "    return XX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SIF_embedding(We, x, w, param):\n",
    "    \"\"\"\n",
    "    Compute the scores between pairs of sentences using weighted average + removing the projection on the first principal component\n",
    "    :param We: We[i,:] is the vector for word i\n",
    "    :param x: x[i, :] are the indices of the words in the i-th sentence\n",
    "    :param w: w[i, :] are the weights for the words in the i-th sentence\n",
    "    :param params.rmpc: if >0, remove the projections of the sentence embeddings to their first principal component\n",
    "    :return: emb, emb[i, :] is the embedding for sentence i\n",
    "    \"\"\"\n",
    "    emb = get_weighted_average(We, x, w)\n",
    "    if  param > 0:\n",
    "        emb = remove_pc(emb, param)\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'U:\\\\Research\\\\Projects\\\\sef\\\\datamining\\\\mlonlineabuse\\\\WorkingFolderActiveAMI\\\\'\n",
    "cur_state = '_4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>0</td>\n",
       "      <td>@hangfirebbq @AlisonMoyet Lolol.. that's so no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>1</td>\n",
       "      <td>@SarahhWaqar @CallmeJaagii Bitch shut the fuck up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>1</td>\n",
       "      <td>Happy 4th of July everyone! Ladies don't fuck ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>1</td>\n",
       "      <td>@lmchristi1 It's a nice butt. But I didn't thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>0</td>\n",
       "      <td>@miidnighthour i mean, i know that ðŸ˜‚ðŸ˜‚ðŸ˜‚ i spent...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "619       0  @hangfirebbq @AlisonMoyet Lolol.. that's so no...\n",
       "1272      1  @SarahhWaqar @CallmeJaagii Bitch shut the fuck up\n",
       "1574      1  Happy 4th of July everyone! Ladies don't fuck ...\n",
       "641       1  @lmchristi1 It's a nice butt. But I didn't thi...\n",
       "1531      0  @miidnighthour i mean, i know that ðŸ˜‚ðŸ˜‚ðŸ˜‚ i spent..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_U = pd.read_csv(PATH+'U'+cur_state+'.csv')\n",
    "df_U.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>1</td>\n",
       "      <td>Told â€œthat tight dress is what makes you a who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>0</td>\n",
       "      <td>@ewnupdates Motlante you power hungry kunt you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>1</td>\n",
       "      <td>@grxmd I dont think this fat whore could even ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>1</td>\n",
       "      <td>â€œOne minute youâ€™re a spooky little witch bitch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>1</td>\n",
       "      <td>@YeenShitCuh Bitch keep my name out your mouth...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "1100      1  Told â€œthat tight dress is what makes you a who...\n",
       "1561      0  @ewnupdates Motlante you power hungry kunt you...\n",
       "1647      1  @grxmd I dont think this fat whore could even ...\n",
       "652       1  â€œOne minute youâ€™re a spooky little witch bitch...\n",
       "388       1  @YeenShitCuh Bitch keep my name out your mouth..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_L = pd.read_csv(PATH+'L'+cur_state+'.csv')\n",
    "df_L.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@priya_ebooks Man: (harasses and stalks woman ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Anybody can dig a hole and plant a tree. But t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>That's the original it came from. But I apprec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>When you've run out of kids to pimp out and yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>The bitch flipped millions for em she deserved...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  @priya_ebooks Man: (harasses and stalks woman ...\n",
       "1      0  Anybody can dig a hole and plant a tree. But t...\n",
       "2      0  That's the original it came from. But I apprec...\n",
       "3      0  When you've run out of kids to pimp out and yo...\n",
       "4      0  The bitch flipped millions for em she deserved..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_U.append(df_L, ignore_index = True)\n",
    "df.reset_index()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basharm\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc_sentences = [df.iloc[idx]['text'].split() for idx in df.index]\n",
    "toc_sentences;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v = Word2Vec(sentences = toc_sentences, max_vocab_size=None, size=200, \n",
    "                               window=5, min_count=1, iter=10, hs=1, \n",
    "                               workers=4, sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basharm\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "vocab = list(model_w2v.wv.vocab)\n",
    "vectors = model_w2v[vocab]\n",
    "#vector = model['author'] # vector for a single word\n",
    "w2v = dict(zip(vocab, vectors))\n",
    "w2v['@'];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2frequency, word2index, index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'woman'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = []\n",
    "[words.extend(df.iloc[idx]['text'].split()) for idx in df.index];\n",
    "words[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2f = Counter(words)\n",
    "w2f;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 10e-3\n",
    "w2w = {}\n",
    "for word in vocab:\n",
    "    w2w[word] = a/(a + w2f[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2i = {}\n",
    "i2w = {}\n",
    "for i,key in enumerate(vocab):\n",
    "    w2i[key] = i\n",
    "    i2w[i] = key\n",
    "w2i;\n",
    "i2w;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "We = np.array(vectors)\n",
    "x = []\n",
    "w = []\n",
    "for toc_sentence in toc_sentences:\n",
    "    x_i = []\n",
    "    w_i = []\n",
    "    for word in toc_sentence:\n",
    "        x_i.append(w2i[word])\n",
    "        w_i.append(w2w[word])\n",
    "    x.append(x_i)\n",
    "    w.append(w_i)\n",
    "x = np.array(x)\n",
    "w = np.array(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embs = SIF_embedding(We, x, w, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.98905345e-05, -2.14459598e-05, -3.82540129e-05, ...,\n",
       "         5.49619736e-05, -1.50128978e-05,  2.40446742e-05],\n",
       "       [ 2.84096030e-06,  1.72700151e-05,  3.73897006e-05, ...,\n",
       "         1.38573537e-05,  1.62785198e-05, -8.63739881e-05],\n",
       "       [ 4.44145038e-05, -9.32318724e-06,  5.05819931e-06, ...,\n",
       "         6.37717797e-06,  6.53118119e-06, -6.15614937e-05],\n",
       "       ...,\n",
       "       [ 2.84741139e-05,  8.53944969e-07,  3.19873161e-05, ...,\n",
       "        -5.79333959e-06,  1.17873289e-05, -5.84563887e-05],\n",
       "       [ 5.25880127e-07,  1.57506371e-05,  6.63278426e-05, ...,\n",
       "        -5.16076179e-05,  9.61174363e-06, -1.08848990e-04],\n",
       "       [ 4.68408766e-05,  6.87340723e-06,  2.39540514e-05, ...,\n",
       "        -6.49857222e-06,  1.16351252e-05, -8.61213949e-05]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(PATH+'sentence_embs.npy', sentence_embs) # save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embs = np.load(PATH+'sentence_embs.npy') # load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.98905345e-05, -2.14459598e-05, -3.82540129e-05, ...,\n",
       "         5.49619736e-05, -1.50128978e-05,  2.40446742e-05],\n",
       "       [ 2.84096030e-06,  1.72700151e-05,  3.73897006e-05, ...,\n",
       "         1.38573537e-05,  1.62785198e-05, -8.63739881e-05],\n",
       "       [ 4.44145038e-05, -9.32318724e-06,  5.05819931e-06, ...,\n",
       "         6.37717797e-06,  6.53118119e-06, -6.15614937e-05],\n",
       "       ...,\n",
       "       [ 2.84741139e-05,  8.53944969e-07,  3.19873161e-05, ...,\n",
       "        -5.79333959e-06,  1.17873289e-05, -5.84563887e-05],\n",
       "       [ 5.25880127e-07,  1.57506371e-05,  6.63278426e-05, ...,\n",
       "        -5.16076179e-05,  9.61174363e-06, -1.08848990e-04],\n",
       "       [ 4.68408766e-05,  6.87340723e-06,  2.39540514e-05, ...,\n",
       "        -6.49857222e-06,  1.16351252e-05, -8.61213949e-05]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please feel free to give your feedback"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".myvenv1",
   "language": "python",
   "name": ".myvenv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
